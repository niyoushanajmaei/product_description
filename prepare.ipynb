{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"prepare.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPS6AxugQRCdrnKAw7qJx9V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ji6bgMhIhhyh"},"source":["This notebook prepares the dataset for description generation\n","\n","\n","1. Copy a batch of excel files to the \"dataset/raw\" folder in the drive.\n","2. Make sure that the first row the files contains the lables of the columns.\n","3. Make sure all the tags are already translated to English\n","\n"]},{"cell_type":"code","metadata":{"id":"JNEsx7NmifKv"},"source":["import pandas as pd\n","from pandas import read_excel\n","from pathlib import Path\n","import numpy as np\n","import lxml.html\n","import string\n","import os\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUaCUg2wihNy"},"source":["def read_batch(read_dir,limit):\n","    dfs = []\n","    c=0\n","    for path in os.listdir(read_dir):\n","        full_path = os.path.join(read_dir, path)\n","        if os.path.isfile(full_path):\n","            dfs.append(read_csv(read_dir,path))\n","            c+=1\n","            print(\"read file #\"+ str(c)) \n","\n","    for i in range(len(dfs)):\n","        dfs[i] = dfs[i].sample(min(limit,len(dfs[i].index)))\n","    \n","    df = pd.concat(dfs)\n","    #print(len(df.index))\n","    df.reset_index(drop=True, inplace=True)\n","    return df\n","\n","\n","def read_csv(path,file_name):\n","    my_sheet = 'BatchImport' \n","    #file_name = '02_batch_import_Dior.xlsx'\n","    df = read_excel(Path(path,file_name), sheet_name = my_sheet,keep_default_na=False)\n","    return clean(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXtiercXjABB"},"source":["def clean(df):\n","    \n","    df[\"material\"] = \"\"\n","\n","    df[\"description_en\"] = df[\"description-en\"]\n","\n","    #name and category were removed.\n","    to_keep=[\"brand\",\"code\",\"madein\",\"subcategory\",\"season\",\n","            \"color\",\"bicolors\",\"gender\",\"neckline\",\"neck_shirt\",\"sleeves\",\"pattern\",\"fastening\",\"sole\",\"pockets\",\"description_en\",\"dimensions\",\"material\",\n","            ,\"neck\",\"sleeve\"]\n","    to_drop=[]\n","    for col in df.columns:\n","        if col not in to_keep:\n","            to_drop.append(col)\n","    df.drop(to_drop, inplace=True, axis=1)\n","    df.drop(df[df.description_en==\"\"].index, inplace=True)\n","    df[\"description_en\"] = df[\"description_en\"].apply(erase_tags)\n","    df = add_features(df)\n","    return df\n","\n","def erase_tags(st):\n","    st = lxml.html.fromstring(st).text_content()\n","    st = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", st)\n","    return re.sub(r\"\\s+\", \" \",st)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CtJH-b31jUSh"},"source":["def add_features(df):\n","    to_delete=[]\n","    materials = []\n","    for index, row in df.iterrows():\n","        # A version of the description, all low case, all punctuations removed\n","        # The possible words are separated after removing the punctuations\n","        desc_procs = row[\"description_en\"].lower().translate(str.maketrans('', '', string.punctuation))\n","        desc_procs = separate_words(desc_procs)\n","    \n","        try:\n","            material = add_material(desc_procs)\n","            materials.append(str(material))\n","            if (material == \"[]\") :\n","                to_delete.append(index)\n","            #print(material)\n","\n","    df[\"material\"] = materials\n","    #print(df.material.to_string(index = False))\n","    print(f\"deleted {len(to_delete)} rows. remaining: {len(df.index)}\")\n","    return df\n","\n","def add_material(desc):\n","    all_materials = [\"canvas\",\"cashmere\",\"chenille\",\"chiffon\",\"cotton\",\"crÃªpe\",\"crepe\",\"damask\",\"georgette\",\"gingham\",\"jersey\",\n","                    \"lace\",\"leather\",\"linen\",\"wool\",\"modal\",\"muslin\",\"organza\",\"polyester\",\"satin\",\"silk\",\"spandex\",\"suede\",\"taffeta\",\n","                    \"toile\",\"tweed\",\"twill\",\"velvet\",\"viscose\",\"synthetic matrials\"]\n","    materials =  []\n","    for m in all_materials:\n","        if m in desc:\n","            materials.append(m)\n","    return materials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xn2JRsjGjjko"},"source":["def clean_txt(st):\n","    st = st.replace('\"','')\n","    st = st.replace('[','')\n","    st = st.replace(']','')\n","    st = st.replace(\"'\",'')\n","    st = st.strip()\n","    return st"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gP5F0P7fhfBz"},"source":["def write(df,write_dir):\n","    path = write_dir + \"test/\"\n","    ref_path = write_dir + \"ref/\"\n","    c=0\n","    #print(df.material.to_string(index = False))\n","    data= df.to_dict('index')\n","    #write the test set with and without the lables to have a reference\n","    for k,value in data.items():\n","        value = {k:v for k,v in value.items() if str(v)!= '' and str(v).strip() != '' and str(v)!='nan' and str(v)!='null' and str(v)!= '[]'}\n","        write_dict(value,ref_path+\"product\"+str(c)+\".txt\",\"n\")\n","        c+=1\n","    c=0\n","    for k,value in data.items():\n","        value = {k:v for k,v in value.items() if str(v)!= '' and str(v).strip() != '' and str(v)!='nan' and str(v)!='null'and str(v)!= '[]'}\n","        write_dict(value,path+\"product\"+str(c)+\".txt\",\"t\")\n","        c+=1 \n","    print(\"writing successful\")\n","\n","# writes the file with format:\n","# when type in \"n\" for normal\n","# {\"tag1\" : \"value1\", \"tag2\": \"value2\", ....} \\n description: \"description_en\" \\n ### \\n\n","# when type is \"t\" for test\n","# {\"tag1\" : \"value1\", \"tag2\": \"value2\", ....} \\n description: \n","def write_dict(dict, path, type):\n","    desc = dict.pop(\"description_en\", None)\n","    code = dict.pop(\"code\",None)\n","    with open(path, 'w') as f:\n","        txt = \"\"\n","        if type == \"n\":\n","            txt += f\"code: {code}\\n\"\n","        txt += f\"features: {str(dict)} \\ndescription: \"\n","        txt = clean_txt(txt)\n","        if type != 'n':\n","            print(txt,file =f,end = '')\n","        if type == \"n\":\n","            txt += desc + \"\\n###\\n\"\n","            print(txt,file =f)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tKd9bR8jjwK1"},"source":["Change the limit of products chosen from each excel file if needed"]},{"cell_type":"code","metadata":{"id":"YwwiPpV6jqaj"},"source":["limit = 1000\n","read_dir = \"/content/drive/MyDrive/dataset/raw/\"\n","write_dir = \"/content/drive/MyDrive/dataset/\"\n","write(read_batch(read_dir,limit),write_dir)"],"execution_count":null,"outputs":[]}]}