{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"prepare.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPtpZGCW8unvCbwru237X+l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ji6bgMhIhhyh"},"source":["#Preparation\n","This notebook prepares the dataset for description generation\n","\n","\n","1. Copy one or multiple excel files to the \"dataset/raw\" folder in the drive.\n","2. Make sure that the first row the files contains the lables of the columns.\n","3. Make sure all the tags (values) are already translated to English\n","4. Make sure the sheet titles are consistent with the value defined in the read_csv function. (default: 'BatchImport')\n","\n","This notebook is compatible with raw data from Griffati and Brandsdistribution catalogs. For other datasets and formats, minor changes may be needed.\n"]},{"cell_type":"code","metadata":{"id":"c4lWqRri0F32","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634216498505,"user_tz":-120,"elapsed":22203,"user":{"displayName":"Niyousha Najmaei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07143616470729540482"}},"outputId":"7b9e2d7d-587e-4714-f2a2-b461bfe3aa8c"},"source":["# Mount the drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"ZmqzYYnv2n2G","executionInfo":{"status":"ok","timestamp":1634216708327,"user_tz":-120,"elapsed":929,"user":{"displayName":"Niyousha Najmaei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07143616470729540482"}}},"source":["!rm -r /content/drive/MyDrive/dataset/test\n","!rm -r /content/drive/MyDrive/dataset/ref\n","!rm -r /content/drive/MyDrive/dataset/gen\n","!mkdir /content/drive/MyDrive/dataset/test\n","!mkdir /content/drive/MyDrive/dataset/ref\n","!mkdir /content/drive/MyDrive/dataset/gen"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNEsx7NmifKv","executionInfo":{"status":"ok","timestamp":1634216499046,"user_tz":-120,"elapsed":21,"user":{"displayName":"Niyousha Najmaei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07143616470729540482"}}},"source":["import pandas as pd\n","from pandas import read_excel\n","from pathlib import Path\n","import numpy as np\n","import lxml.html\n","import string\n","import os\n","import re"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUaCUg2wihNy","executionInfo":{"status":"ok","timestamp":1634216499047,"user_tz":-120,"elapsed":21,"user":{"displayName":"Niyousha Najmaei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07143616470729540482"}}},"source":["def read_batch(read_dir,limit):\n","    dfs = []\n","    c=0\n","    for path in os.listdir(read_dir):\n","        full_path = os.path.join(read_dir, path)\n","        if os.path.isfile(full_path):\n","            dfs.append(read_csv(read_dir,path))\n","            c+=1\n","            print(\"read file #\"+ str(c)) \n","\n","    for i in range(len(dfs)):\n","        dfs[i] = dfs[i].sample(min(limit,len(dfs[i].index)))\n","    \n","    df = pd.concat(dfs)\n","    #print(len(df.index))\n","    df.reset_index(drop=True, inplace=True)\n","    return df\n","\n","\n","def read_csv(path,file_name):\n","    my_sheet = 'BatchImport' \n","    #file_name = '02_batch_import_Dior.xlsx'\n","    df = read_excel(Path(path,file_name), sheet_name = my_sheet,keep_default_na=False)\n","    return clean(df)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXtiercXjABB","executionInfo":{"status":"ok","timestamp":1634216499048,"user_tz":-120,"elapsed":21,"user":{"displayName":"Niyousha Najmaei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07143616470729540482"}}},"source":["def clean(df):\n","    \n","    df[\"material\"] = \"\"\n","\n","    df[\"description_en\"] = df[\"description-en\"]\n","\n","    #name and category were removed.\n","    to_keep=[\"brand\",\"code\",\"madein\",\"subcategory\",\"season\",\n","            \"color\",\"bicolors\",\"gender\",\"neckline\",\"neck_shirt\",\"sleeves\",\"pattern\",\"fastening\",\"sole\",\"pockets\",\"description_en\",\"dimensions\",\"material\"\n","            ,\"neck\",\"sleeve\"]\n","    to_drop=[]\n","    for col in df.columns:\n","        if col not in to_keep:\n","            to_drop.append(col)\n","    df.drop(to_drop, inplace=True, axis=1)\n","    df.drop(df[df.description_en==\"\"].index, inplace=True)\n","    df[\"description_en\"] = df[\"description_en\"].apply(erase_tags)\n","    df = add_features(df)\n","    return df\n","\n","def erase_tags(st):\n","    st = lxml.html.fromstring(st).text_content()\n","    st = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", st)\n","    return re.sub(r\"\\s+\", \" \",st)\n","\n","def separate_words(st):\n","    return re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", st)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BBI7Y-u2tst2"},"source":["If more features are required to be added, use https://github.com/niyoushanajmaei/product_description_process/blob/main/extract.py for relevant functions."]},{"cell_type":"code","metadata":{"id":"CtJH-b31jUSh","executionInfo":{"status":"ok","timestamp":1634216499049,"user_tz":-120,"elapsed":20,"user":{"displayName":"Niyousha Najmaei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07143616470729540482"}}},"source":["def add_features(df):\n","    to_delete=[]\n","    materials = []\n","    for index, row in df.iterrows():\n","        # A version of the description, all low case, all punctuations removed\n","        # The possible words are separated after removing the punctuations\n","        desc_procs = row[\"description_en\"].lower().translate(str.maketrans('', '', string.punctuation))\n","        desc_procs = separate_words(desc_procs)\n","    \n","        material = add_material(desc_procs)\n","        materials.append(str(material))\n","        if (material == \"[]\") :\n","            to_delete.append(index)\n","        #print(material)\n","\n","    df[\"material\"] = materials\n","    #print(df.material.to_string(index = False))\n","    print(f\"deleted {len(to_delete)} rows. remaining: {len(df.index)}\")\n","    return df\n","\n","def add_material(desc):\n","    all_materials = [\"canvas\",\"cashmere\",\"chenille\",\"chiffon\",\"cotton\",\"crÃªpe\",\"crepe\",\"damask\",\"georgette\",\"gingham\",\"jersey\",\n","                    \"lace\",\"leather\",\"linen\",\"wool\",\"modal\",\"muslin\",\"organza\",\"polyester\",\"satin\",\"silk\",\"spandex\",\"suede\",\"taffeta\",\n","                    \"toile\",\"tweed\",\"twill\",\"velvet\",\"viscose\",\"synthetic matrials\"]\n","    materials =  []\n","    for m in all_materials:\n","        if m in desc:\n","            materials.append(m)\n","    return materials"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xn2JRsjGjjko","executionInfo":{"status":"ok","timestamp":1634216499051,"user_tz":-120,"elapsed":20,"user":{"displayName":"Niyousha Najmaei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07143616470729540482"}}},"source":["def clean_txt(st):\n","    st = st.replace('\"','')\n","    st = st.replace('[','')\n","    st = st.replace(']','')\n","    st = st.replace(\"'\",'')\n","    st = st.strip()\n","    return st"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"gP5F0P7fhfBz","executionInfo":{"status":"ok","timestamp":1634216499052,"user_tz":-120,"elapsed":20,"user":{"displayName":"Niyousha Najmaei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07143616470729540482"}}},"source":["def write(df,write_dir):\n","    path = write_dir + \"test/\"\n","    ref_path = write_dir + \"ref/\"\n","    c=0\n","    #print(df.material.to_string(index = False))\n","    data= df.to_dict('index')\n","    #write the test set with and without the lables to have a reference\n","    for k,value in data.items():\n","        value = {k:v for k,v in value.items() if str(v)!= '' and str(v).strip() != '' and str(v)!='nan' and str(v)!='null' and str(v)!= '[]'}\n","        write_dict(value,ref_path+\"product\"+str(c)+\".txt\",\"n\")\n","        c+=1\n","    c=0\n","    for k,value in data.items():\n","        value = {k:v for k,v in value.items() if str(v)!= '' and str(v).strip() != '' and str(v)!='nan' and str(v)!='null'and str(v)!= '[]'}\n","        write_dict(value,path+\"product\"+str(c)+\".txt\",\"t\")\n","        c+=1 \n","    print(\"writing successful\")\n","\n","# writes the file with format:\n","# when type in \"n\" for normal\n","# {\"tag1\" : \"value1\", \"tag2\": \"value2\", ....} \\n description: \"description_en\" \\n ### \\n\n","# when type is \"t\" for test\n","# {\"tag1\" : \"value1\", \"tag2\": \"value2\", ....} \\n description: \n","def write_dict(dict, path, type):\n","    desc = dict.pop(\"description_en\", None)\n","    code = dict.pop(\"code\",None)\n","    with open(path, 'w') as f:\n","        txt = \"\"\n","        if type == \"n\":\n","            txt += f\"code: {code}\\n\"\n","        txt += f\"features: {str(dict)} \\ndescription: \"\n","        txt = clean_txt(txt)\n","        if type != 'n':\n","            print(txt,file =f,end = '')\n","        if type == \"n\":\n","            txt += desc + \"\\n###\\n\"\n","            print(txt,file =f)\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZpGKnqkkv4i-","executionInfo":{"status":"ok","timestamp":1634216499053,"user_tz":-120,"elapsed":19,"user":{"displayName":"Niyousha Najmaei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07143616470729540482"}}},"source":["#make an empty checkpoint file used in the generation notebook\n","def ckpt_file(dir):\n","    with open(dir+\"checkpoint.txt\",\"w\") as f:\n","        pass"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tKd9bR8jjwK1"},"source":["Change the limit of products chosen from each excel file if needed"]},{"cell_type":"code","metadata":{"id":"xqj5qXIa1q2J","executionInfo":{"status":"ok","timestamp":1634216499877,"user_tz":-120,"elapsed":841,"user":{"displayName":"Niyousha Najmaei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07143616470729540482"}}},"source":["!rm -r /content/drive/MyDrive/dataset/ref/\n","!rm -r /content/drive/MyDrive/dataset/test/\n","!mkdir /content/drive/MyDrive/dataset/ref/\n","!mkdir /content/drive/MyDrive/dataset/test/"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"YwwiPpV6jqaj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634216502265,"user_tz":-120,"elapsed":2392,"user":{"displayName":"Niyousha Najmaei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07143616470729540482"}},"outputId":"20adc3fc-21ee-49a6-a480-522df8fd5052"},"source":["limit = 1000\n","read_dir = \"/content/drive/MyDrive/dataset/raw/\"\n","write_dir = \"/content/drive/MyDrive/dataset/\"\n","write(read_batch(read_dir,limit),write_dir)\n","ckpt_file(write_dir)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["deleted 0 rows. remaining: 4\n","read file #1\n","writing successful\n"]}]}]}